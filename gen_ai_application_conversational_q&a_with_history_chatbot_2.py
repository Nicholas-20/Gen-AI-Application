# -*- coding: utf-8 -*-
"""Gen AI application Conversational Q&A with history chatbot 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jyzk_MmaYsvWz3_kHnPjVeTsbrLGBSjZ
"""

!python --version

!pip install streamlit

!pip install google-generativeai

!pip install python-dotenv

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# from dotenv import load_dotenv
# load_dotenv()
# import streamlit as st
# import os
# import google.generativeai as genai
# import secret_api
# 
# GOOGLE_API_KEY=os.getenv("GOOGLE_API_KEY")
# genai.configure(api_key=GOOGLE_API_KEY)
# model=genai.GenerativeModel("gemini-pro")
# chat=model.start_chat(history=[])
# 
# def get_gemini_response(question):
#   response=chat.send_message(question,stream=True)
#   return response
# #Initializing the streamlit app
# st.set_page_config(page_title="Q&A DEMO")
# st.header("GEMINI APPLICATION")
# if 'chat_history' not in st.session_state:
#   st.session_state['chat_history']=[]
# 
# input=st.text_input("Input:",key="input")
# submit=st.button("Ask the question")
# 
# if submit and input:
#   response=get_gemini_response(input)
#   st.session_state['chat_history'].append(("You",input))
#   st.subheader("Response is")
#   for chunk in response:
#     st.write(chunk.text)
#     st.session_state["chat_history"].append(("bot",chunk.text))
# 
# st.subheader("The chat history is")
# for role,text in st.session_state["chat_history"]:
#   st.write(f"{role}:{text}")

!streamlit run app.py & npx localtunnel --port 8501



